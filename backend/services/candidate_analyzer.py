"""
Servicio de an√°lisis de candidatos usando IA
Aplica principios √©ticos estrictos y formato de respuesta espec√≠fico
"""
import os
import logging
from typing import List, Optional
from string import Template
from openai import OpenAI
from anthropic import Anthropic
import google.generativeai as genai
from dotenv import load_dotenv

from models.schemas import (
    CandidateAnalysisResult,
    ObjectiveCriterion,
    ConfidenceLevel,
    CandidateDocument
)

load_dotenv()
logger = logging.getLogger(__name__)


class CandidateAnalyzer:
    """
    Analiza candidatos usando IA, aplicando principios √©ticos estrictos.
    
    Formato de respuesta:
    (a) Recomendaci√≥n
    (b) Criterios objetivos
    (c) Nivel de confianza / incertidumbre
    """
    
    def __init__(self):
        # Inicializar clientes de IA
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY")) if os.getenv("OPENAI_API_KEY") else None
        self.anthropic_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY")) if os.getenv("ANTHROPIC_API_KEY") else None
        
        if os.getenv("GOOGLE_API_KEY"):
            genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
            self.gemini_configured = True
        else:
            self.gemini_configured = False
        
        # Usar modelos con contextos grandes por defecto para soportar CVs y JDs sin restricciones
        self.default_model = os.getenv("DEFAULT_AI_MODEL", "gpt-4-turbo-preview")  # 128k tokens
    
    async def analyze_batch(
        self,
        job_description: str,
        candidates: List[CandidateDocument],
        model_id: Optional[str] = None
    ) -> List[CandidateAnalysisResult]:
        """
        Analiza m√∫ltiples candidatos a partir del texto extra√≠do de sus CVs.
        """
        # Validar que hay al menos una API key configurada
        if not self.openai_client and not self.anthropic_client and not self.gemini_configured:
            raise ValueError(
                "No hay servicio de IA configurado. "
                "Configura al menos una de: OPENAI_API_KEY, ANTHROPIC_API_KEY, o GOOGLE_API_KEY"
            )
        
        # Validar que hay candidatos
        if not candidates or len(candidates) == 0:
            raise ValueError("No se proporcionaron candidatos para analizar")
        
        # Validar que hay job description
        if not job_description or not job_description.strip():
            raise ValueError("No se proporcion√≥ la descripci√≥n del puesto (Job Description)")

        analyses: List[CandidateAnalysisResult] = []

        for candidate in candidates:
            try:
                prompt = self._build_ethical_prompt(
                    job_description=job_description,
                    cv_content=candidate.content,
                    filename=candidate.filename
                )

                raw_response = await self._call_ai(prompt, model_id=model_id)
                
                # Logging de la respuesta de IA para debugging
                logger.info(f"‚úÖ Respuesta de IA recibida para {candidate.filename} ({len(raw_response)} caracteres)")
                logger.debug(f"üìÑ Primeros 500 chars de respuesta: {raw_response[:500]}")
                
                analysis = self._parse_response(
                    raw_response=raw_response,
                    candidate_id=candidate.candidateId,
                    filename=candidate.filename
                )
                analyses.append(analysis)
                logger.info(f"‚úÖ An√°lisis completado exitosamente para {candidate.filename}")
            except KeyError as ke:
                # Capturar KeyError espec√≠ficamente antes de que se propague
                error_msg = f"Error de formato en respuesta de IA: {str(ke)}"
                error_type = "KeyError"
                logger.error(
                    f"‚ùå KeyError analizando candidato {candidate.candidateId or candidate.filename}: {str(ke)}"
                )
                logger.error(f"üìã Traceback completo del KeyError:", exc_info=True)
                # Logging adicional para diagn√≥stico
                logger.error(f"üîç Este error indica que la respuesta de IA no ten√≠a el formato JSON esperado")
                logger.error(f"üîç Revisa los logs anteriores para ver la respuesta completa de la IA")
                
                # Crear un resultado de error espec√≠fico para KeyError
                recommendation_msg = (
                    f"Error al procesar la respuesta de IA para este candidato. "
                    "El formato de la respuesta no fue el esperado. "
                    "Por favor, intenta nuevamente. Si el problema persiste, contacta al administrador del sistema."
                )
                
                analyses.append(CandidateAnalysisResult(
                    candidateId=candidate.candidateId,
                    filename=candidate.filename,
                    recommendation=recommendation_msg,
                    objective_criteria=[
                        ObjectiveCriterion(
                            name="Error t√©cnico (KeyError)",
                            value=f"Error de formato en respuesta de IA: {str(ke)[:300]}",
                            weight=0.0
                        )
                    ],
                    confidence_level=ConfidenceLevel.INSUFFICIENT,
                    confidence_explanation=f"Error durante el an√°lisis: KeyError. La respuesta de IA no ten√≠a el formato esperado.",
                    missing_information=["An√°lisis no completado debido a error t√©cnico en formato de respuesta"],
                    ethical_compliance=True,
                    risks=[{
                        "category": "cumplimiento",
                        "level": "alto",
                        "description": f"Error t√©cnico durante el an√°lisis (KeyError): {str(ke)[:200]}"
                    }]
                ))
            except Exception as e:
                error_msg = str(e)
                error_type = type(e).__name__
                logger.error(
                    f"Error analizando candidato {candidate.candidateId or candidate.filename}: {error_type} - {error_msg}"
                )
                logger.debug(f"Traceback completo del error: {repr(e)}", exc_info=True)
                
                # Crear un resultado de error m√°s informativo
                # No mencionar tama√±o ya que no hay restricciones de tama√±o
                recommendation_msg = (
                    f"Error al analizar este candidato: {error_msg[:200]}. "
                    "Por favor, revisa el CV e intenta nuevamente. "
                    "Si el problema persiste, contacta al administrador del sistema."
                )
                
                analyses.append(CandidateAnalysisResult(
                    candidateId=candidate.candidateId,
                    filename=candidate.filename,
                    recommendation=recommendation_msg,
                    objective_criteria=[
                        ObjectiveCriterion(
                            name="Error t√©cnico",
                            value=f"Error tipo {error_type}: {error_msg[:300]}",
                            weight=0.0
                        )
                    ],
                    confidence_level=ConfidenceLevel.INSUFFICIENT,
                    confidence_explanation=f"Error durante el an√°lisis: {error_type}. {error_msg[:200]}",
                    missing_information=["An√°lisis no completado debido a error t√©cnico"],
                    ethical_compliance=True,
                    risks=[{
                        "category": "cumplimiento",
                        "level": "alto",
                        "description": f"Error t√©cnico durante el an√°lisis ({error_type}): {error_msg[:200]}"
                    }]
                ))

        return analyses

    def _estimate_tokens(self, text: str) -> int:
        """
        Estima el n√∫mero de tokens en un texto.
        Aproximaci√≥n: 1 token ‚âà 4 caracteres (conservador para espa√±ol)
        """
        return len(text) // 4
    
    def _truncate_text_intelligently(self, text: str, max_tokens: int) -> str:
        """
        Trunca texto de manera inteligente, manteniendo el inicio y final.
        El inicio suele tener informaci√≥n clave (t√≠tulo, resumen, requisitos principales).
        El final puede tener informaci√≥n adicional importante.
        """
        max_chars = max_tokens * 4  # Convertir tokens a caracteres
        
        if len(text) <= max_chars:
            return text
        
        # Calcular cu√°nto espacio tenemos
        # Dividir: 60% inicio, 40% final
        start_chars = int(max_chars * 0.6)
        end_chars = int(max_chars * 0.4)
        
        # Obtener las partes
        start_part = text[:start_chars]
        end_part = text[-end_chars:]
        
        # Buscar el √∫ltimo punto/punto y coma/salto de l√≠nea antes del corte para no cortar palabras
        start_cut_pos = start_part.rfind('.')
        if start_cut_pos == -1:
            start_cut_pos = start_part.rfind(';')
        if start_cut_pos == -1:
            start_cut_pos = start_part.rfind('\n')
        if start_cut_pos == -1:
            start_cut_pos = len(start_part)
        else:
            start_cut_pos += 1  # Incluir el car√°cter de corte
        
        # Buscar el primer punto/punto y coma/salto de l√≠nea despu√©s del inicio del final
        end_cut_pos = end_part.find('.')
        if end_cut_pos == -1:
            end_cut_pos = end_part.find(';')
        if end_cut_pos == -1:
            end_cut_pos = end_part.find('\n')
        if end_cut_pos == -1:
            end_cut_pos = 0
        else:
            end_cut_pos += 1  # Incluir el car√°cter de corte
        
        # Ajustar las partes
        start_part = text[:start_cut_pos]
        
        # Para el final, tomar desde el final menos los caracteres disponibles
        # Si encontramos un punto de corte, empezar desde ah√≠
        if end_cut_pos > 0:
            # Empezar desde el punto de corte encontrado
            end_start_idx = len(text) - end_chars + end_cut_pos
            end_part = text[end_start_idx:]
        else:
            # No encontramos punto de corte, tomar los √∫ltimos caracteres
            end_part = text[-end_chars:]
        
        return f"{start_part}\n\n[... contenido truncado para cumplir l√≠mite de tokens ...]\n\n{end_part}"

    def _build_ethical_prompt(
        self,
        job_description: str,
        cv_content: str,
        filename: str
    ) -> str:
        """
        Construye un prompt que aplica estrictamente los principios √©ticos
        y realiza comparaci√≥n directa y estricta entre JD y CV.
        Trunca el contenido si es necesario para cumplir con el l√≠mite de tokens.
        """
        # SIN RESTRICCIONES DE TAMA√ëO: Usar modelos con contextos grandes
        # GPT-4 Turbo: 128k tokens, Claude Sonnet 4: 200k tokens, Gemini 2.5 Pro: 1M tokens
        # Dejamos un margen para la respuesta (10k tokens) y usamos el resto para el prompt
        # Esto permite analizar CVs y JDs de cualquier tama√±o sin truncamiento
        MAX_PROMPT_TOKENS = 100000  # 100k tokens para el prompt (suficiente para CVs muy largos)
        
        # Construir el prompt base (sin JD y CV)
        # Usar $job_description, $cv_content, $filename como placeholders para Template
        prompt_base = """Eres un asistente de Recursos Humanos para agente-rh. Tu funci√≥n es COMPARAR DIRECTAMENTE el CV del candidato con los REQUISITOS ESPEC√çFICOS del Job Description.

M√âTODO DE AN√ÅLISIS (OBLIGATORIO - SEGUIR EN ORDEN):

PASO 1: IDENTIFICA REQUISITOS CLAVE del Job Description:
   - T√≠tulo del puesto y √°rea funcional (ej: "Desarrollador Backend", "Analista Financiero")
   - A√±os de experiencia requeridos (espec√≠ficos, no aproximados)
   - Educaci√≥n/certificaciones obligatorias (t√≠tulos, certificaciones espec√≠ficas)
   - Habilidades t√©cnicas espec√≠ficas (lenguajes, herramientas, tecnolog√≠as)
   - Competencias o conocimientos especializados (dominios, metodolog√≠as)
   - Responsabilidades principales (qu√© har√° en el puesto)

PASO 2: VERIFICA √ÅREA FUNCIONAL (CR√çTICO):
   - Identifica el √°rea funcional del JD (ej: Desarrollo de Software, Finanzas, Marketing, RH)
   - Identifica el √°rea funcional del CV (basado en experiencia previa)
   - Si las √°reas son COMPLETAMENTE DIFERENTES y NO transferibles:
     * Ejemplo: JD es "Desarrollador Backend" y CV es "Dise√±ador UX" ‚Üí "insufficient"
     * Ejemplo: JD es "Analista Financiero" y CV es "Marketing" ‚Üí "insufficient"
     * Ejemplo: JD es "Gerente de RH" y CV es "Desarrollador" ‚Üí "insufficient"
   - Si las √°reas son DIFERENTES pero POTENCIALMENTE TRANSFERIBLES:
     * Ejemplo: JD es "Analista de Datos en Banca" y CV es "Analista de Datos en Retail" ‚Üí evaluar habilidades transferibles
     * Ejemplo: JD es "Desarrollador Python" y CV es "Desarrollador Java" ‚Üí evaluar si las habilidades son transferibles

PASO 3: COMPARA PUNTO POR PUNTO con el CV:
   Para CADA requisito del JD, verifica:
   - ¬øEl candidato tiene la experiencia requerida? (a√±os EXACTOS, tipo de experiencia ESPEC√çFICO)
   - ¬øTiene la educaci√≥n/certificaciones necesarias? (t√≠tulo ESPEC√çFICO, certificaci√≥n ESPEC√çFICA)
   - ¬øPosee las habilidades t√©cnicas mencionadas en el JD? (lenguaje/herramienta ESPEC√çFICA)
   - ¬øSu experiencia previa est√° relacionada con las responsabilidades del puesto? (responsabilidades ESPEC√çFICAS)

PASO 4: EVAL√öA COINCIDENCIAS REALES (S√â ESTRICTO):
   - Coincidencia EXACTA: El CV menciona ESPEC√çFICAMENTE lo que el JD requiere
     * Ejemplo: JD requiere "5 a√±os en Python", CV muestra "6 a√±os en Python" ‚Üí EXACTA
   - Coincidencia PARCIAL: El CV tiene algo relacionado pero NO exacto
     * Ejemplo: JD requiere "5 a√±os en Python", CV muestra "3 a√±os en Java" ‚Üí PARCIAL (lenguaje diferente)
     * Ejemplo: JD requiere "Ingenier√≠a en Sistemas", CV muestra "Ingenier√≠a en Computaci√≥n" ‚Üí PARCIAL (similar pero no exacto)
   - Sin coincidencia: El CV NO menciona nada relacionado
     * Ejemplo: JD requiere "Python", CV muestra solo "Java y C++" ‚Üí NINGUNA
     * Ejemplo: JD requiere "Experiencia en banca", CV muestra solo "Retail" ‚Üí NINGUNA (a menos que sea transferible)

PASO 5: CALCULA M√âTRICAS DE COINCIDENCIA:
   - Cuenta cu√°ntos requisitos OBLIGATORIOS del JD se cumplen
   - Cuenta cu√°ntos requisitos OBLIGATORIOS del JD NO se cumplen
   - Calcula el porcentaje: (requisitos cumplidos / total requisitos obligatorios) √ó 100
   - Si el porcentaje es < 50%, el nivel DEBE ser "low" o "insufficient"
   - Si el porcentaje es 50-70%, el nivel DEBE ser "medium" o "low"
   - Si el porcentaje es > 70% Y hay coincidencias EXACTAS, puede ser "high" o "medium"

PASO 6: PENALIZA AUSENCIAS (OBLIGATORIO):
   - Si faltan requisitos OBLIGATORIOS del JD, el candidato NO puede tener un score alto
   - Si el CV est√° en un √°rea completamente diferente, usa "insufficient"
   - Si hay m√°s requisitos NO cumplidos que cumplidos, el nivel DEBE ser "low" o "insufficient"
   - Si faltan M√ÅS DE 2 requisitos obligatorios, el nivel NO puede ser "high"
   - Si el √°rea funcional es diferente y NO transferible, el nivel DEBE ser "insufficient"

REGLAS ESTRICTAS DE √âTICA Y EQUIDAD:

1. PROP√ìSITO LIMITADO: Solo analiza informaci√≥n laboral (experiencia, educaci√≥n, certificaciones, logros). 
   IMPORTANTE: NO tomas decisiones finales. Tu funci√≥n es proporcionar an√°lisis objetivo y recomendaciones 
   basadas en criterios medibles. La decisi√≥n final de contratar, rechazar o entrevistar SIEMPRE la toma un humano.

2. VARIABLES V√ÅLIDAS: Considera SOLO:
   - Experiencia profesional (a√±os, tipo, relevancia)
   - Educaci√≥n y formaci√≥n (t√≠tulos, √°reas de estudio)
   - Certificaciones profesionales
   - Habilidades t√©cnicas espec√≠ficas
   - Logros profesionales medibles
   
   PROHIBIDO usar, inferir o mencionar:
   - Edad, g√©nero, raza, etnia, color de piel
   - Religi√≥n, creencias, orientaci√≥n sexual
   - Estado civil, situaci√≥n familiar, hijos
   - Nacionalidad, origen √©tnico, lugar de nacimiento
   - Discapacidad, condici√≥n m√©dica, salud
   - Apariencia f√≠sica, peso, altura
   - Nombre que pueda indicar g√©nero u origen
   - Cualquier dato que no sea directamente relevante para el desempe√±o laboral

3. EQUIDAD Y NO DISCRIMINACI√ìN:
   - Eval√∫a SOLO competencias y habilidades relevantes para el puesto
   - NO penalices por "sobrecalificaci√≥n" o "subcalificaci√≥n" si las habilidades son transferibles
   - NO asumas que ciertos tipos de experiencia son "mejores" que otros sin justificaci√≥n objetiva
   - Considera experiencia transferible de manera justa (ej: experiencia en retail puede ser relevante para banca en ciertos roles)
   - NO uses estereotipos sobre industrias, empresas o tipos de experiencia
   - Eval√∫a habilidades, no el "prestigio" de universidades o empresas previas

4. LENGUAJE INCLUSIVO Y NEUTRO:
   - Usa lenguaje que no asuma g√©nero (ej: "la persona" en lugar de "el candidato")
   - Evita t√©rminos que puedan tener connotaciones negativas sobre grupos
   - NO uses t√©rminos como "joven", "maduro", "fresco", "experimentado" de manera que pueda indicar edad
   - NO uses t√©rminos que puedan indicar g√©nero o caracter√≠sticas personales

3. COMPARACI√ìN ESTRICTA:
   - NO asumas que un candidato es "bueno" solo porque tiene experiencia general
   - REQUIERE coincidencias espec√≠ficas entre JD y CV
   - Si el JD pide "5 a√±os en desarrollo Python" y el CV tiene "3 a√±os en Java", es INSUFICIENTE
   - Si el JD pide "Ingenier√≠a en Sistemas" y el CV tiene "Administraci√≥n", es INSUFICIENTE
   - Si el JD pide "Experiencia en banca" y el CV tiene "Experiencia en retail", eval√∫a si es TRANSFERIBLE o NO

4. NIVELES DE CONFIANZA (USA ESTRICTAMENTE):
   - "high": El CV cumple con TODOS los requisitos principales del JD y tiene experiencia directa relevante
   - "medium": El CV cumple con la mayor√≠a de requisitos pero faltan algunos importantes o la experiencia es parcialmente relevante
   - "low": El CV cumple con pocos requisitos o la experiencia es en un √°rea diferente pero potencialmente transferible
   - "insufficient": El CV NO cumple con los requisitos principales, est√° en un √°rea completamente diferente, o falta informaci√≥n cr√≠tica

5. RAZONAMIENTO VERIFICABLE: 
   - Para cada criterio, indica QU√â del JD se compara con QU√â del CV
   - Ejemplo: "JD requiere: 5 a√±os en Python. CV muestra: 2 a√±os en Java. Coincidencia: PARCIAL (lenguaje diferente)"
   - NO uses lenguaje vago como "tiene experiencia" sin especificar qu√© y cu√°nta

6. LENGUAJE NEUTRAL: 
   - Usa descripciones objetivas y comparativas
   - PROHIBIDO usar adjetivos subjetivos como: excelente, malo, bueno, terrible, perfecto, incre√≠ble, etc.
   - Usa: "cumple", "no cumple", "parcialmente", "espec√≠ficamente menciona", "no menciona"

7. PESOS DE CRITERIOS:
   - Asigna pesos m√°s altos (0.4-0.5) a requisitos OBLIGATORIOS del JD
   - Asigna pesos medios (0.2-0.3) a requisitos importantes pero no cr√≠ticos
   - Asigna pesos bajos (0.1-0.15) a requisitos deseables o complementarios
   - La suma de pesos debe aproximarse a 1.0

EJEMPLOS DE COMPARACI√ìN (REFERENCIA):

EJEMPLO 1 - COINCIDENCIA EXACTA (BUENO):
JD requiere: "5 a√±os en desarrollo Python, experiencia en Django, Ingenier√≠a en Sistemas"
CV muestra: "6 a√±os desarrollando en Python, 4 a√±os usando Django, Ingenier√≠a en Sistemas"
Resultado: Coincidencia EXACTA en todos los requisitos ‚Üí "high"

EJEMPLO 2 - SIN COINCIDENCIA (MALO):
JD requiere: "5 a√±os en desarrollo Python, experiencia en banca"
CV muestra: "3 a√±os en Java, 2 a√±os en C++, experiencia en retail"
Resultado: Lenguaje diferente (Python vs Java), industria diferente (banca vs retail) ‚Üí "insufficient"

EJEMPLO 3 - COINCIDENCIA PARCIAL:
JD requiere: "5 a√±os en desarrollo Python"
CV muestra: "3 a√±os en Java, conocimiento b√°sico de Python"
Resultado: Experiencia insuficiente (3 a√±os vs 5 requeridos), lenguaje parcialmente relacionado ‚Üí "low"

EJEMPLO 4 - √ÅREA FUNCIONAL DIFERENTE:
JD requiere: "Desarrollador Backend Python"
CV muestra: "Dise√±ador UX con 5 a√±os de experiencia"
Resultado: √Årea funcional completamente diferente (desarrollo vs dise√±o) ‚Üí "insufficient"

EJEMPLO 5 - TRANSFERIBLE:
JD requiere: "Analista de Datos en sector financiero, Python, SQL"
CV muestra: "Analista de Datos en retail, Python, SQL, 4 a√±os"
Resultado: Mismas habilidades t√©cnicas, industria diferente pero transferible ‚Üí "medium"

JOB DESCRIPTION (referencia principal - REQUISITOS A CUMPLIR):

$job_description

CV ANALIZADO ($filename - COMPARAR CON REQUISITOS ARRIBA):

$cv_content

INSTRUCCIONES FINALES (SEGUIR EN ORDEN):

1. PRIMERO: Verifica el √°rea funcional. Si es completamente diferente y NO transferible ‚Üí "insufficient" inmediatamente

2. SEGUNDO: Compara CADA requisito OBLIGATORIO del JD con el CV de manera objetiva y justa
   - Para cada requisito, indica: "JD requiere X, CV muestra Y, Coincidencia: EXACTA/PARCIAL/NINGUNA"

3. TERCERO: Calcula m√©tricas:
   - Total requisitos obligatorios en JD: ___
   - Requisitos cumplidos (EXACTA o PARCIAL relevante): ___
   - Requisitos NO cumplidos: ___
   - Porcentaje de cumplimiento: ___%
   - Si porcentaje < 50% ‚Üí "insufficient" o "low"
   - Si porcentaje 50-70% ‚Üí "low" o "medium"
   - Si porcentaje > 70% y hay coincidencias EXACTAS ‚Üí "medium" o "high"

4. CUARTO: Si el CV NO menciona algo que el JD requiere, ind√≠calo claramente en "missing_information" pero sin juicios de valor

5. QUINTO: Si el CV est√° en un √°rea diferente, eval√∫a transferibilidad:
   - Si las habilidades t√©cnicas son las mismas pero la industria es diferente ‚Üí puede ser transferible
   - Si las habilidades t√©cnicas son diferentes ‚Üí NO es transferible
   - Si el √°rea funcional es diferente (ej: desarrollo vs dise√±o) ‚Üí NO es transferible

6. SEXTO: Reglas de penalizaci√≥n ESTRICTAS:
   - Si hay M√ÅS requisitos NO cumplidos que cumplidos ‚Üí nivel DEBE ser "low" o "insufficient"
   - Si faltan M√ÅS DE 2 requisitos obligatorios ‚Üí nivel NO puede ser "high"
   - Si el √°rea funcional es diferente y NO transferible ‚Üí nivel DEBE ser "insufficient"
   - NO des puntajes altos por "buena actitud", "experiencia general" o "potencial" si no cumple requisitos espec√≠ficos

7. S√âPTIMO: EQUIDAD Y NO DISCRIMINACI√ìN:
   - Si un candidato tiene experiencia transferible pero en diferente industria, eval√∫a las habilidades t√©cnicas, NO el "prestigio" de la industria
   - NO penalices por tener experiencia en industrias "menos prestigiosas" si las habilidades son relevantes
   - Eval√∫a competencias, NO el nombre de la universidad o empresa previa

8. OCTAVO: VERIFICA SESGOS antes de responder:
   - ¬øEstoy asumiendo que ciertos tipos de experiencia son "mejores" sin justificaci√≥n objetiva?
   - ¬øEstoy penalizando por industria o tipo de empresa sin raz√≥n t√©cnica?
   - ¬øEstoy usando estereotipos sobre tipos de educaci√≥n o formaci√≥n?
   - ¬øMi an√°lisis est√° basado en hechos objetivos o en prejuicios?

EVALUACI√ìN DE RIESGOS (OBLIGATORIO):

Identifica y categoriza los riesgos encontrados en el an√°lisis. Los riesgos pueden ser:

1. RIESGOS T√âCNICOS:
   - Falta de habilidades t√©cnicas espec√≠ficas requeridas
   - Experiencia insuficiente en tecnolog√≠as cr√≠ticas
   - Brechas en conocimientos t√©cnicos obligatorios

2. RIESGOS DE EXPERIENCIA:
   - A√±os de experiencia por debajo del m√≠nimo requerido
   - Falta de experiencia en industria/sector espec√≠fico
   - Ausencia de experiencia en responsabilidades clave

3. RIESGOS DE FORMACI√ìN:
   - Falta de educaci√≥n/certificaciones obligatorias
   - T√≠tulo/√°rea de estudio no alineada con requisitos
   - Certificaciones vencidas o no mencionadas

4. RIESGOS DE √ÅREA FUNCIONAL:
   - √Årea funcional completamente diferente y no transferible
   - Cambio de carrera sin justificaci√≥n de transferibilidad
   - Falta de experiencia en el tipo de rol

5. RIESGOS DE CUMPLIMIENTO:
   - M√∫ltiples requisitos obligatorios no cumplidos
   - Porcentaje de cumplimiento muy bajo (<50%)
   - M√°s requisitos faltantes que cumplidos

Para cada riesgo identificado, indica:
- "category": "t√©cnico|experiencia|formaci√≥n|√°rea_funcional|cumplimiento"
- "level": "alto|medio|bajo" (alto: bloqueante, medio: importante, bajo: menor)
- "description": "Descripci√≥n espec√≠fica del riesgo y su impacto"

FORMATO DE RESPUESTA (OBLIGATORIO):

Responde EXACTAMENTE en este formato JSON:

{{
  "recommendation": "(a) Tu recomendaci√≥n objetiva. DEBE incluir: 1) √Årea funcional del JD vs CV y si es transferible, 2) Lista espec√≠fica de qu√© requisitos del JD cumple (con detalles), 3) Lista espec√≠fica de qu√© requisitos NO cumple (con detalles), 4) Porcentaje estimado de cumplimiento. Si no cumple requisitos principales, ind√≠calo claramente.",
  "objective_criteria": [
    {{
      "name": "Nombre del criterio (ej: 'Experiencia en Python')",
      "value": "Comparaci√≥n espec√≠fica: JD requiere X, CV muestra Y. Coincidencia: EXACTA/PARCIAL/NINGUNA. Justificaci√≥n: [por qu√© es exacta/parcial/ninguna]",
      "weight": 0.35
    }}
  ],
  "confidence_level": "high|medium|low|insufficient",
  "confidence_explanation": "Explicaci√≥n detallada DEBE incluir: 1) √Årea funcional: [coincide/diferente/transferible], 2) Requisitos cumplidos: X de Y, 3) Porcentaje de cumplimiento: Z%, 4) Raz√≥n del nivel asignado basado en las m√©tricas calculadas",
  "missing_information": ["Requisito OBLIGATORIO del JD que NO est√° en el CV (espec√≠fico)", "Otro requisito obligatorio faltante (espec√≠fico)"],
  "risks": [
    {{
      "category": "t√©cnico|experiencia|formaci√≥n|√°rea_funcional|cumplimiento",
      "level": "alto|medio|bajo",
      "description": "Descripci√≥n espec√≠fica del riesgo y su impacto potencial en el desempe√±o del puesto"
    }}
  ]
}}

VALIDACI√ìN FINAL (ANTES DE RESPONDER):

‚úì Verifiqu√© el √°rea funcional: [coincide/diferente/transferible]
‚úì Cont√© requisitos obligatorios del JD: [n√∫mero]
‚úì Cont√© requisitos cumplidos: [n√∫mero]
‚úì Calcul√© porcentaje de cumplimiento: [%]
‚úì Verifiqu√© que el nivel de confianza coincida con las m√©tricas
‚úì Verifiqu√© que no haya sesgos en mi evaluaci√≥n
‚úì Verifiqu√© que no use lenguaje subjetivo
‚úì Verifiqu√© que no infiera atributos personales
‚úì Verifiqu√© que cada criterio muestre comparaci√≥n espec√≠fica JD vs CV

IMPORTANTE:
- La recomendaci√≥n DEBE mencionar: √°rea funcional, requisitos cumplidos (lista), requisitos NO cumplidos (lista), porcentaje de cumplimiento
- Los criterios DEBEN mostrar: "JD requiere X, CV muestra Y, Coincidencia: [tipo], Justificaci√≥n: [raz√≥n]"
- El nivel de confianza DEBE reflejar las m√©tricas calculadas (porcentaje de cumplimiento)
- Si faltan requisitos OBLIGATORIOS, el nivel DEBE ser "low" o "insufficient"
- Si el porcentaje de cumplimiento es < 50%, el nivel DEBE ser "insufficient" o "low"
- Si el √°rea funcional es diferente y NO transferible, el nivel DEBE ser "insufficient"
- NO uses lenguaje subjetivo ni adjetivos de valor
- NO infieras atributos personales
- NO asumas que "experiencia general" es suficiente si el JD requiere algo espec√≠fico
- NO des puntajes altos sin coincidencias reales y espec√≠ficas
- Recuerda: esto es APOYO, no una decisi√≥n final"""
        
        # SIN RESTRICCIONES: Usar CV y JD completos sin truncamiento
        # Los modelos modernos (GPT-4 Turbo, Claude Sonnet 4, Gemini 2.5 Pro) tienen contextos
        # suficientemente grandes para manejar CVs y JDs de cualquier tama√±o razonable
        logger.info(
            f"Analizando candidato {filename} con JD de {len(job_description)} caracteres "
            f"y CV de {len(cv_content)} caracteres (sin restricciones de tama√±o)"
        )
        
        # Usar Template en lugar de .format() para evitar problemas con llaves {}
        # Template usa $variable en lugar de {variable}, lo que es m√°s seguro cuando el contenido tiene llaves
        # NO necesitamos escapar llaves porque Template no las interpreta como placeholders
        try:
            template = Template(prompt_base)
            final_prompt = template.safe_substitute(
                job_description=job_description,
                cv_content=cv_content,
                filename=filename
            )
        except Exception as e:
            # Si hay un error, registrar informaci√≥n de diagn√≥stico
            logger.error(f"‚ùå Error al construir prompt con Template: {type(e).__name__} - {str(e)}")
            logger.error(f"üîç JD tiene {len(job_description)} caracteres")
            logger.error(f"üîç CV tiene {len(cv_content)} caracteres")
            logger.error(f"üîç JD (primeros 500 chars): {job_description[:500]}")
            logger.error(f"üîç CV (primeros 500 chars): {cv_content[:500]}")
            raise
        
        # Logging informativo (no restrictivo)
        final_tokens = self._estimate_tokens(final_prompt)
        logger.debug(
            f"Prompt final para {filename}: ~{final_tokens} tokens estimados "
            f"(JD: ~{self._estimate_tokens(job_description)}, CV: ~{self._estimate_tokens(cv_content)})"
        )
        
        return final_prompt
    
    async def _call_ai(self, prompt: str, model_id: Optional[str] = None) -> str:
        """
        Llama al servicio de IA configurado
        """
        model = (model_id or self.default_model).lower()

        if model.startswith("gpt") and self.openai_client:
            return await self._call_openai(prompt, model_id or self.default_model)
        elif model.startswith("claude") and self.anthropic_client:
            return await self._call_anthropic(prompt, model_id or self.default_model)
        elif model.startswith("gemini") and self.gemini_configured:
            return await self._call_gemini(prompt, model_id or self.default_model)
        else:
            raise ValueError("No hay servicio de IA configurado o modelo no v√°lido")
    
    async def _call_openai(self, prompt: str, model: str) -> str:
        """Llamar a OpenAI"""
        try:
            # Mapear modelos a versiones con contextos grandes
            model_map = {
                "gpt-4": "gpt-4-turbo-preview",  # 128k tokens
                "gpt-4-turbo": "gpt-4-turbo-preview",  # 128k tokens
                "gpt-4-turbo-preview": "gpt-4-turbo-preview",  # 128k tokens
            }
            actual_model = model_map.get(model.lower(), model)
            
            response = self.openai_client.chat.completions.create(
                model=actual_model,
                messages=[
                    {
                        "role": "system",
                        "content": "Eres un asistente √©tico de Recursos Humanos especializado en comparaci√≥n estricta entre Job Descriptions y CVs. Eval√∫as candidatos comparando DIRECTAMENTE los requisitos del JD con la experiencia del CV. Eres ESTRICTO: no das puntajes altos si no hay coincidencias reales. Aplicas principios de objetividad, neutralidad, equidad, no discriminaci√≥n y privacidad. NO usas, infieres ni mencionas datos personales protegidos. Eval√∫as solo competencias y habilidades relevantes para el desempe√±o laboral. Eres consciente de sesgos y los evitas activamente. IMPORTANTE: NO tomas decisiones finales, solo proporcionas an√°lisis y recomendaciones para que un humano tome la decisi√≥n."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=4000,  # Aumentado para respuestas m√°s completas
            )
            content = response.choices[0].message.content
            if not content or content.strip() == "":
                raise ValueError("La respuesta de OpenAI est√° vac√≠a")
            return content
        except Exception as e:
            logger.error(f"Error llamando OpenAI: {e}")
            raise
    
    async def _call_anthropic(self, prompt: str, model: str) -> str:
        """Llamar a Anthropic Claude"""
        try:
            # Claude Sonnet 4 tiene 200k tokens de contexto, suficiente para CVs y JDs grandes
            model_map = {
                "claude-opus-4": "claude-opus-4-20250514",  # 200k tokens
                "claude-sonnet-4": "claude-sonnet-4-20250514",  # 200k tokens
                "claude-haiku-3.5": "claude-3-5-haiku-20241022",  # 200k tokens
            }
            anthropic_model = model_map.get(model.lower(), "claude-sonnet-4-20250514")
            
            message = self.anthropic_client.messages.create(
                model=anthropic_model,
                max_tokens=4000,  # Aumentado para respuestas m√°s completas
                temperature=0.1,
                system="Eres un asistente √©tico de Recursos Humanos especializado en comparaci√≥n estricta entre Job Descriptions y CVs. Eval√∫as candidatos comparando DIRECTAMENTE los requisitos del JD con la experiencia del CV. Eres ESTRICTO: no das puntajes altos si no hay coincidencias reales. Aplicas principios de objetividad, neutralidad, equidad, no discriminaci√≥n y privacidad. NO usas, infieres ni mencionas datos personales protegidos. Eval√∫as solo competencias y habilidades relevantes para el desempe√±o laboral. Eres consciente de sesgos y los evitas activamente. IMPORTANTE: NO tomas decisiones finales, solo proporcionas an√°lisis y recomendaciones para que un humano tome la decisi√≥n.",
                messages=[{"role": "user", "content": prompt}],
            )
            if not message.content or len(message.content) == 0:
                raise ValueError("La respuesta de Anthropic est√° vac√≠a")
            content = message.content[0].text
            if not content or content.strip() == "":
                raise ValueError("La respuesta de Anthropic est√° vac√≠a")
            return content
        except Exception as e:
            logger.error(f"Error llamando Anthropic: {e}")
            raise
    
    async def _call_gemini(self, prompt: str, model: str) -> str:
        """Llamar a Google Gemini"""
        try:
            # Gemini 2.5 Pro tiene 1M tokens de contexto, m√°s que suficiente
            model_map = {
                "gemini-2.5-pro": "gemini-2.5-pro",  # 1M tokens
                "gemini-2.5-flash": "gemini-2.5-flash",  # 1M tokens
                "gemini-1.5-pro": "gemini-1.5-pro",  # 1M tokens
            }
            gemini_model_id = model_map.get(model.lower(), "gemini-2.5-pro")
            
            genai_model = genai.GenerativeModel(gemini_model_id)
            response = genai_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.1,
                    max_output_tokens=4000,  # Aumentado para respuestas m√°s completas
                ),
                safety_settings=[
                    {
                        "category": "HARM_CATEGORY_HARASSMENT",
                        "threshold": "BLOCK_NONE"
                    },
                    {
                        "category": "HARM_CATEGORY_HATE_SPEECH",
                        "threshold": "BLOCK_NONE"
                    },
                    {
                        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        "threshold": "BLOCK_NONE"
                    },
                    {
                        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                        "threshold": "BLOCK_NONE"
                    }
                ]
            )
            if not response or not response.text:
                raise ValueError("La respuesta de Gemini est√° vac√≠a")
            content = response.text
            if not content or content.strip() == "":
                raise ValueError("La respuesta de Gemini est√° vac√≠a")
            return content
        except Exception as e:
            logger.error(f"Error llamando Gemini: {e}")
            raise
    
    def _normalize_dict_keys(self, obj):
        """
        Normaliza recursivamente todas las claves de un diccionario,
        removiendo espacios, saltos de l√≠nea y caracteres problem√°ticos.
        Esto previene KeyError por claves con formato extra√±o como '\n "recommendation"'
        """
        if isinstance(obj, dict):
            normalized = {}
            for key, value in obj.items():
                try:
                    # Normalizar la clave de forma MUY agresiva
                    normalized_key = str(key)
                    
                    # Paso 1: Remover TODOS los saltos de l√≠nea, retornos de carro y tabs
                    normalized_key = normalized_key.replace('\n', '').replace('\r', '').replace('\t', '')
                    
                    # Paso 2: Remover espacios al inicio y final
                    normalized_key = normalized_key.strip()
                    
                    # Paso 3: Remover comillas al inicio y final (puede haber m√∫ltiples)
                    # Manejar casos como: '\n  "recommendation"' o '"recommendation"' o "'recommendation'"
                    while len(normalized_key) >= 2:
                        if (normalized_key.startswith('"') and normalized_key.endswith('"')) or \
                           (normalized_key.startswith("'") and normalized_key.endswith("'")):
                            normalized_key = normalized_key[1:-1].strip()
                        else:
                            break
                    
                    # Paso 4: Remover espacios m√∫ltiples y normalizar
                    normalized_key = ' '.join(normalized_key.split())
                    
                    # Paso 5: Si despu√©s de todo esto la clave est√° vac√≠a, usar un nombre por defecto
                    if not normalized_key:
                        normalized_key = f"key_{len(normalized)}"
                    
                    # Paso 6: Si hay claves duplicadas despu√©s de normalizar, agregar sufijo
                    if normalized_key in normalized:
                        counter = 1
                        original_key = normalized_key
                        while normalized_key in normalized:
                            normalized_key = f"{original_key}_{counter}"
                            counter += 1
                    
                    # Normalizar recursivamente el valor
                    normalized[normalized_key] = self._normalize_dict_keys(value)
                    
                except Exception as e:
                    # Si hay cualquier error normalizando esta clave, usar un nombre seguro
                    logger.warning(f"‚ö†Ô∏è Error normalizando clave '{key}': {str(e)}. Usando nombre por defecto.")
                    safe_key = f"key_{len(normalized)}_{hash(str(key)) % 10000}"
                    normalized[safe_key] = self._normalize_dict_keys(value)
            
            return normalized
        elif isinstance(obj, list):
            return [self._normalize_dict_keys(item) for item in obj]
        else:
            return obj
    
    def _parse_response(
        self,
        raw_response: str,
        candidate_id: Optional[str],
        filename: str
    ) -> CandidateAnalysisResult:
        """
        Parsea la respuesta de IA al formato requerido
        """
        import json
        import re
        
        # Validar que la respuesta no est√© vac√≠a
        if not raw_response or not raw_response.strip():
            logger.error(f"Respuesta de IA vac√≠a para candidato {candidate_id or filename}")
            raise ValueError("La respuesta de IA est√° vac√≠a")
        
        # Limpiar la respuesta: remover markdown code blocks si existen
        cleaned_response = raw_response.strip()
        
        # Remover markdown code blocks (```json ... ``` o ``` ... ```)
        cleaned_response = re.sub(r'```(?:json)?\s*\n?', '', cleaned_response, flags=re.IGNORECASE)
        cleaned_response = re.sub(r'```\s*$', '', cleaned_response, flags=re.MULTILINE)
        cleaned_response = cleaned_response.strip()
        
        # Verificar si la respuesta parece estar incompleta (termina abruptamente)
        if cleaned_response and not cleaned_response.endswith('}') and '{' in cleaned_response:
            # Contar llaves para ver si est√° balanceado
            open_braces = cleaned_response.count('{')
            close_braces = cleaned_response.count('}')
            if open_braces > close_braces:
                logger.warning(
                    f"Respuesta de IA parece incompleta para candidato {candidate_id or filename}. "
                    f"Llaves abiertas: {open_braces}, cerradas: {close_braces}"
                )
        
        # Intentar m√∫ltiples estrategias para extraer JSON
        data = None
        json_str = None
        
        # Estrategia 1: Buscar JSON entre llaves (m√°s espec√≠fico, busca desde la primera { hasta la √∫ltima })
        json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', cleaned_response, re.DOTALL)
        if json_match:
            json_str = json_match.group()
        else:
            # Estrategia 2: Buscar desde la primera { hasta el final
            json_match = re.search(r'\{.*$', cleaned_response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
        
        # Si encontramos un candidato a JSON, intentar parsearlo
        if json_str:
            try:
                # Limpiar el JSON string de posibles caracteres problem√°ticos
                json_str_clean = json_str.strip()
                # Remover posibles saltos de l√≠nea al inicio que puedan causar problemas
                while json_str_clean.startswith('\n') or json_str_clean.startswith('\r'):
                    json_str_clean = json_str_clean[1:].strip()
                
                # Intentar parsear
                data = json.loads(json_str_clean)
                
                # LOGGING: Mostrar claves originales ANTES de normalizar
                if isinstance(data, dict):
                    original_keys_before = list(data.keys())
                    logger.info(f"üîë Claves originales del JSON (antes de normalizar): {original_keys_before}")
                    logger.info(f"üîë Tipos de claves: {[type(k).__name__ for k in original_keys_before]}")
                    logger.info(f"üîë Representaci√≥n de claves: {[repr(k) for k in original_keys_before[:5]]}")
                
                # NORMALIZAR TODAS LAS CLAVES DEL DICCIONARIO RECURSIVAMENTE INMEDIATAMENTE
                # Esto previene KeyError por claves con formato extra√±o como '\n "recommendation"'
                if isinstance(data, dict):
                    data = self._normalize_dict_keys(data)
                    
                    # LOGGING: Mostrar claves despu√©s de normalizar
                    normalized_keys_after = list(data.keys())
                    logger.info(f"‚úÖ Claves normalizadas del JSON (despu√©s de normalizar): {normalized_keys_after}")
                
            except json.JSONDecodeError as e:
                logger.warning(f"Error parseando JSON (estrategia 1): {str(e)}")
                logger.debug(f"JSON intentado (primeros 500 chars): {json_str[:500]}...")
                
                # Estrategia 3: Intentar encontrar JSON v√°lido buscando desde el inicio
                # Buscar el primer { y luego encontrar el } correspondiente balanceado
                start_idx = cleaned_response.find('{')
                if start_idx != -1:
                    brace_count = 0
                    end_idx = start_idx
                    for i in range(start_idx, len(cleaned_response)):
                        if cleaned_response[i] == '{':
                            brace_count += 1
                        elif cleaned_response[i] == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                end_idx = i + 1
                                break
                    
                    if brace_count == 0:
                        json_str = cleaned_response[start_idx:end_idx].strip()
                        # Limpiar nuevamente
                        while json_str.startswith('\n') or json_str.startswith('\r'):
                            json_str = json_str[1:].strip()
                        try:
                            data = json.loads(json_str)
                            # NORMALIZAR TODAS LAS CLAVES DESPU√âS DE PARSEAR INMEDIATAMENTE
                            if isinstance(data, dict):
                                data = self._normalize_dict_keys(data)
                        except json.JSONDecodeError as e2:
                            logger.warning(f"Error parseando JSON (estrategia 2): {str(e2)}")
                            logger.warning(f"JSON intentado (primeros 1000 chars): {json_str[:1000]}...")
                            logger.warning(f"JSON intentado (√∫ltimos 500 chars): {json_str[-500:] if len(json_str) > 500 else json_str}")
                            logger.warning(f"Posici√≥n del error: {e2.pos if hasattr(e2, 'pos') else 'N/A'}")
                            
                            # Estrategia 4: Intentar reparar JSON com√∫n malformado
                            try:
                                json_str_fixed = json_str
                                
                                # Reparaci√≥n 1: Remover trailing commas antes de } o ]
                                json_str_fixed = re.sub(r',\s*}', '}', json_str_fixed)
                                json_str_fixed = re.sub(r',\s*]', ']', json_str_fixed)
                                
                                # Reparaci√≥n 2: Remover comentarios de l√≠nea (// comentario)
                                json_str_fixed = re.sub(r'//.*?$', '', json_str_fixed, flags=re.MULTILINE)
                                
                                # Reparaci√≥n 3: Remover comentarios de bloque (/* comentario */)
                                json_str_fixed = re.sub(r'/\*.*?\*/', '', json_str_fixed, flags=re.DOTALL)
                                
                                # Reparaci√≥n 4: Escapar caracteres de control no v√°lidos
                                json_str_fixed = json_str_fixed.replace('\x00', '').replace('\x01', '').replace('\x02', '')
                                
                                # Reparaci√≥n 5: Arreglar comillas simples que deber√≠an ser dobles en keys
                                json_str_fixed = re.sub(r"'(\w+)'\s*:", r'"\1":', json_str_fixed)
                                
                                # Reparaci√≥n 6: Arreglar strings con comillas simples que deber√≠an ser dobles
                                json_str_fixed = re.sub(r":\s*'([^']*)'", r': "\1"', json_str_fixed)
                                
                                # Reparaci√≥n 7: Remover saltos de l√≠nea dentro de strings (mantener solo espacios)
                                # Esto es complejo, mejor intentar parsear primero
                                
                                data = json.loads(json_str_fixed)
                                if isinstance(data, dict):
                                    data = self._normalize_dict_keys(data)
                                    logger.info("JSON reparado exitosamente usando estrategia 4")
                            except Exception as e3:
                                logger.warning(f"Error reparando JSON (estrategia 4): {str(e3)}")
                                
                                # Estrategia 5: Intentar extraer JSON de texto mixto (texto + JSON)
                                try:
                                    # Buscar el bloque JSON m√°s grande posible
                                    # Encontrar todos los bloques { ... } y tomar el m√°s grande
                                    json_blocks = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', cleaned_response, re.DOTALL)
                                    if json_blocks:
                                        # Ordenar por tama√±o y tomar el m√°s grande
                                        largest_block = max(json_blocks, key=len)
                                        data = json.loads(largest_block)
                                        if isinstance(data, dict):
                                            data = self._normalize_dict_keys(data)
                                            logger.info("JSON extra√≠do exitosamente usando estrategia 5 (bloque m√°s grande)")
                                except Exception as e4:
                                    logger.warning(f"Error en estrategia 5: {str(e4)}")
                                    logger.debug(f"Respuesta completa (primeros 2000 chars): {raw_response[:2000]}")
                    else:
                        logger.warning(f"JSON no balanceado: {brace_count} llaves abiertas sin cerrar")
        
        # Si logramos parsear el JSON, procesarlo
        if data:
            # Validar que data sea un diccionario ANTES de cualquier acceso
            if not isinstance(data, dict):
                logger.error(
                    f"El JSON parseado no es un diccionario para candidato {candidate_id or filename}. "
                    f"Tipo: {type(data)}, Valor: {str(data)[:200]}"
                )
                # Continuar al fallback
                data = None
            else:
                # Logging para debugging: mostrar las claves originales antes de normalizar
                original_keys = list(data.keys())
                logger.debug(
                    f"Claves originales del JSON parseado para {candidate_id or filename}: {original_keys}"
                )
                # La normalizaci√≥n ya se hizo arriba, solo validar campos
                # Validar que tenga al menos algunos campos esperados
                if not any(key in data for key in ["recommendation", "objective_criteria", "confidence_level"]):
                    logger.warning(
                        f"El JSON parseado no tiene los campos esperados para candidato {candidate_id or filename}. "
                        f"Campos encontrados: {list(data.keys()) if isinstance(data, dict) else 'N/A'}"
                    )
        
        # Si logramos parsear el JSON y es un diccionario v√°lido, procesarlo
        if data and isinstance(data, dict):
            try:
                # Crear un wrapper seguro que siempre use .get() y maneje claves normalizadas
                # Esto previene cualquier KeyError, incluso si hay claves con formato extra√±o
                safe_data = {}
                # Usar .items() con try/except para manejar cualquier formato de clave
                try:
                    for key, value in data.items():
                        try:
                            # Normalizar la clave para buscar
                            normalized_key = str(key).strip().replace('\n', '').replace('\r', '')
                            # Remover comillas
                            while (normalized_key.startswith('"') and normalized_key.endswith('"')) or \
                                  (normalized_key.startswith("'") and normalized_key.endswith("'")):
                                if len(normalized_key) >= 2:
                                    normalized_key = normalized_key[1:-1].strip()
                                else:
                                    break
                            # Si despu√©s de normalizar la clave est√° vac√≠a, usar un nombre por defecto
                            if not normalized_key:
                                normalized_key = f"key_{len(safe_data)}"
                            # Guardar con clave normalizada
                            safe_data[normalized_key] = value
                        except (KeyError, AttributeError, TypeError) as e:
                            # Si hay cualquier error al procesar esta clave, registrar y continuar
                            logger.warning(f"Error normalizando clave '{key}': {type(e).__name__} - {str(e)}. Omitiendo esta clave.")
                            continue
                        except Exception as e:
                            # Si hay cualquier otro error al procesar esta clave, registrar y continuar
                            logger.warning(f"Error inesperado normalizando clave '{key}': {type(e).__name__} - {str(e)}. Omitiendo esta clave.")
                            continue
                    
                    # Usar safe_data en lugar de data para todos los accesos
                    data = safe_data
                except (KeyError, AttributeError, TypeError) as e:
                    # Si hay un error al iterar sobre data.items(), registrar y usar data original
                    logger.error(f"Error iterando sobre claves del diccionario: {type(e).__name__} - {str(e)}")
                    logger.error(f"Tipo de data: {type(data)}, Claves disponibles: {list(data.keys()) if isinstance(data, dict) else 'N/A'}")
                    # Continuar con data original pero usando solo .get()
                    pass
                
                # Convertir criterios
                criteria = []
                objective_criteria_data = data.get("objective_criteria", [])
                if not isinstance(objective_criteria_data, list):
                    logger.warning(f"objective_criteria no es una lista, es {type(objective_criteria_data)}")
                    objective_criteria_data = []
                
                for crit in objective_criteria_data:
                    if not isinstance(crit, dict):
                        logger.warning(f"Criterio no es un diccionario: {type(crit)}")
                        continue
                    criteria.append(ObjectiveCriterion(
                        name=crit.get("name", ""),
                        value=crit.get("value", ""),
                        weight=crit.get("weight")
                    ))
                
                # Determinar nivel de confianza
                conf_str = data.get("confidence_level", "medium").lower()
                if conf_str == "high":
                    confidence = ConfidenceLevel.HIGH
                elif conf_str == "low":
                    confidence = ConfidenceLevel.LOW
                elif conf_str == "insufficient":
                    confidence = ConfidenceLevel.INSUFFICIENT
                else:
                    confidence = ConfidenceLevel.MEDIUM
                
                # VALIDACI√ìN POST-AN√ÅLISIS: Ajustar nivel si hay inconsistencias
                missing_info = data.get("missing_information", [])
                if not isinstance(missing_info, list):
                    logger.warning(f"missing_information no es una lista, es {type(missing_info)}")
                    missing_info = []
                missing_count = len(missing_info) if missing_info else 0
                
                # Si el nivel es "high" pero hay m√°s de 2 requisitos faltantes, ajustar
                if confidence == ConfidenceLevel.HIGH and missing_count > 2:
                    logger.warning(
                        f"Inconsistencia detectada: confidence_level='high' pero hay {missing_count} requisitos faltantes. "
                        f"Ajustando a 'medium' para candidato {candidate_id or filename}"
                    )
                    confidence = ConfidenceLevel.MEDIUM
                
                # Si el nivel es "high" o "medium" pero hay m√°s de 3 requisitos faltantes, ajustar a "low"
                if confidence in [ConfidenceLevel.HIGH, ConfidenceLevel.MEDIUM] and missing_count > 3:
                    logger.warning(
                        f"Inconsistencia detectada: confidence_level='{confidence.value}' pero hay {missing_count} requisitos faltantes. "
                        f"Ajustando a 'low' para candidato {candidate_id or filename}"
                    )
                    confidence = ConfidenceLevel.LOW
                
                # Si hay m√°s de 5 requisitos faltantes, forzar "insufficient"
                if missing_count > 5:
                    logger.warning(
                        f"Muchos requisitos faltantes ({missing_count}). Ajustando a 'insufficient' para candidato {candidate_id or filename}"
                    )
                    confidence = ConfidenceLevel.INSUFFICIENT
                
                # Verificar que haya criterios objetivos
                if not criteria or len(criteria) == 0:
                    logger.warning(f"No se encontraron criterios objetivos para {candidate_id or filename}")
                    # Crear criterio gen√©rico
                    criteria = [
                        ObjectiveCriterion(
                            name="An√°lisis general",
                            value="Revisi√≥n manual requerida - criterios no especificados",
                            weight=1.0
                        )
                    ]
                
                # Extraer riesgos identificados
                risks_data = data.get("risks", [])
                if not isinstance(risks_data, list):
                    logger.warning(f"risks no es una lista, es {type(risks_data)}")
                    risks_data = []
                risks = []
                if risks_data:
                    for risk in risks_data:
                        if isinstance(risk, dict):
                            risks.append({
                                "category": risk.get("category", "cumplimiento"),
                                "level": risk.get("level", "medio"),
                                "description": risk.get("description", "Riesgo no especificado")
                            })
                
                # Si no hay riesgos expl√≠citos pero hay muchos requisitos faltantes, generar riesgos autom√°ticos
                if not risks and missing_count > 0:
                    if missing_count > 3:
                        risks.append({
                            "category": "cumplimiento",
                            "level": "alto",
                            "description": f"Faltan {missing_count} requisitos obligatorios del JD, lo que indica bajo nivel de alineaci√≥n con el puesto"
                        })
                    elif missing_count > 1:
                        risks.append({
                            "category": "cumplimiento",
                            "level": "medio",
                            "description": f"Faltan {missing_count} requisitos obligatorios del JD que podr√≠an afectar el desempe√±o"
                        })
                
                # Si el √°rea funcional es diferente, agregar riesgo
                confidence_explanation = data.get("confidence_explanation", "")
                if not isinstance(confidence_explanation, str):
                    confidence_explanation = str(confidence_explanation) if confidence_explanation else ""
                confidence_explanation_lower = confidence_explanation.lower()
                if "√°rea funcional" in confidence_explanation_lower and ("diferente" in confidence_explanation_lower or "no transferible" in confidence_explanation_lower):
                    risks.append({
                        "category": "√°rea_funcional",
                        "level": "alto",
                        "description": "El √°rea funcional del CV no coincide con el JD y no es transferible"
                    })
                
                # Obtener recommendation de forma segura
                recommendation = data.get("recommendation", "An√°lisis no disponible")
                if not isinstance(recommendation, str):
                    recommendation = str(recommendation) if recommendation else "An√°lisis no disponible"
                
                # Obtener confidence_explanation de forma segura
                confidence_explanation_final = data.get("confidence_explanation", "")
                if not isinstance(confidence_explanation_final, str):
                    confidence_explanation_final = str(confidence_explanation_final) if confidence_explanation_final else ""
                
                return CandidateAnalysisResult(
                    candidateId=candidate_id,
                    filename=filename,
                    recommendation=recommendation,
                    objective_criteria=criteria,
                    confidence_level=confidence,
                    confidence_explanation=confidence_explanation_final,
                    missing_information=missing_info,
                    ethical_compliance=True,
                    risks=risks if risks else None
                )
            except KeyError as ke:
                # Capturar KeyError espec√≠ficamente
                logger.error(
                    f"KeyError al procesar datos parseados para {candidate_id or filename}: {str(ke)}"
                )
                logger.error(f"Claves disponibles en data: {list(data.keys()) if isinstance(data, dict) else 'N/A'}")
                logger.error(f"Tipo de datos: {type(data)}, Contenido: {str(data)[:500] if data else 'None'}")
                # Continuar al fallback
                data = None
            except (ValueError, TypeError, AttributeError) as ve:
                # Capturar errores de tipo y valor
                logger.error(
                    f"Error de tipo/valor al procesar datos parseados para {candidate_id or filename}: {type(ve).__name__} - {str(ve)}"
                )
                logger.error(f"Tipo de datos: {type(data)}, Contenido: {str(data)[:500] if data else 'None'}")
                # Continuar al fallback
                data = None
            except Exception as e:
                # Capturar cualquier otro error
                error_type = type(e).__name__
                error_msg = str(e)
                logger.error(
                    f"Error inesperado procesando datos parseados para {candidate_id or filename}: {error_type} - {error_msg}"
                )
                logger.error(f"Tipo de datos: {type(data)}, Contenido: {str(data)[:500] if data else 'None'}")
                logger.debug(f"Traceback completo:", exc_info=True)
                # Continuar al fallback
                data = None
        
        # Fallback: respuesta b√°sica cuando no se puede parsear o procesar
        if data is None:
            # Logging detallado para diagn√≥stico - MEJORADO PARA VISIBILIDAD
            logger.error("=" * 80)
            logger.error(f"‚ùå ERROR: No se pudo parsear respuesta de IA para candidato: {candidate_id or filename}")
            logger.error("=" * 80)
            logger.error(f"üìè Longitud total de respuesta: {len(raw_response)} caracteres")
            logger.error(f"üìÑ Respuesta completa de IA (primeros 3000 chars):")
            logger.error("-" * 80)
            logger.error(raw_response[:3000])
            logger.error("-" * 80)
            if len(raw_response) > 3000:
                logger.error(f"üìÑ Respuesta completa de IA (√∫ltimos 1000 chars):")
                logger.error("-" * 80)
                logger.error(raw_response[-1000:])
                logger.error("-" * 80)
            logger.error("=" * 80)
            
            # Intentar extraer informaci√≥n parcial incluso si el JSON est√° malformado
            partial_data = {}
            
            # Buscar campos clave usando regex como √∫ltimo recurso
            recommendation_match = re.search(r'"recommendation"\s*:\s*"([^"]+)"', raw_response, re.IGNORECASE | re.DOTALL)
            if recommendation_match:
                partial_data["recommendation"] = recommendation_match.group(1)
                logger.info("Se encontr√≥ 'recommendation' usando regex")
            
            confidence_match = re.search(r'"confidence_level"\s*:\s*"([^"]+)"', raw_response, re.IGNORECASE)
            if confidence_match:
                partial_data["confidence_level"] = confidence_match.group(1)
                logger.info("Se encontr√≥ 'confidence_level' usando regex")
            
            # Si encontramos al menos algunos datos parciales, intentar usarlos
            if partial_data:
                logger.info(f"Datos parciales extra√≠dos: {list(partial_data.keys())}")
                try:
                    # Intentar construir un resultado con datos parciales
                    conf_str = partial_data.get("confidence_level", "medium").lower()
                    if conf_str == "high":
                        confidence = ConfidenceLevel.HIGH
                    elif conf_str == "low":
                        confidence = ConfidenceLevel.LOW
                    elif conf_str == "insufficient":
                        confidence = ConfidenceLevel.INSUFFICIENT
                    else:
                        confidence = ConfidenceLevel.MEDIUM
                    
                    return CandidateAnalysisResult(
                        candidateId=candidate_id,
                        filename=filename,
                        recommendation=partial_data.get("recommendation", "An√°lisis parcial disponible. La respuesta de IA tuvo problemas de formato pero se pudo extraer informaci√≥n b√°sica."),
                        objective_criteria=[
                            ObjectiveCriterion(
                                name="An√°lisis parcial",
                                value="Se extrajo informaci√≥n parcial de la respuesta de IA. Algunos campos pueden estar incompletos.",
                                weight=0.5
                            )
                        ],
                        confidence_level=confidence,
                        confidence_explanation="An√°lisis parcial debido a problemas de formato en la respuesta de IA. Se recomienda revisar manualmente.",
                        missing_information=["Formato completo de respuesta de IA"],
                        ethical_compliance=True,
                        risks=[{
                            "category": "cumplimiento",
                            "level": "medio",
                            "description": "La respuesta de IA tuvo problemas de formato, se extrajo informaci√≥n parcial"
                        }]
                    )
                except Exception as e:
                    logger.error(f"Error construyendo resultado parcial: {str(e)}")
                    # Continuar con el fallback normal
        
        return CandidateAnalysisResult(
            candidateId=candidate_id,
            filename=filename,
            recommendation="An√°lisis requiere revisi√≥n manual debido a formato de respuesta inesperado de la IA. Por favor, intenta nuevamente o revisa el CV.",
            objective_criteria=[
                ObjectiveCriterion(
                    name="Error de procesamiento",
                    value=f"La respuesta de IA no pudo ser parseada correctamente. Error: {str(raw_response[:200]) if raw_response else 'Respuesta vac√≠a'}",
                    weight=0.0
                )
            ],
            confidence_level=ConfidenceLevel.INSUFFICIENT,
            confidence_explanation="No se pudo procesar la respuesta de IA correctamente. La respuesta no estaba en el formato JSON esperado.",
            missing_information=["Formato de respuesta v√°lido de IA"],
            ethical_compliance=True,
            risks=[{
                "category": "cumplimiento",
                "level": "alto",
                "description": "No se pudo procesar correctamente la respuesta de IA, requiere revisi√≥n manual o reintento"
            }]
        )
